{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# General libraries for scientific computation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Graphic libraries\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Model validation\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Feature extraction\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "# Model evaluation\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Other tools\n",
    "from sklearn.pipeline import Pipeline\n",
    "import time\n",
    "#import string\n",
    "\n",
    "# Visualize decision-tree\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "import pydotplus\n",
    "\n",
    "\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General funcions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### Plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This code has been take from the official documentation of scikit-learn and it was modified\n",
    "# for the porpuses of the present work\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    plt.FormatStrFormatter('%.2f')\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, \"{:.2f}\".format(cm[i, j]),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### Plot Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def func_learning_curve(est, X_train, y_train, save_result=False):\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator=est, X=X_train, y=y_train,\n",
    "                                               train_sizes=np.linspace(0.1, 1.0, 10), cv=10, n_jobs=-1)\n",
    "\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    train_std = np.std(train_scores, axis=1)\n",
    "    test_mean = np.mean(test_scores, axis=1)\n",
    "    test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    plt.plot(train_sizes, train_mean, color='blue', marker='o',\n",
    "             markersize=5, label='training accuracy')\n",
    "\n",
    "    plt.fill_between(train_sizes, train_mean + train_std,\n",
    "                     train_mean - train_std, alpha=0.15, color='blue')\n",
    "\n",
    "    plt.plot(train_sizes, test_mean, color='green', linestyle='--',\n",
    "             marker='s', markersize=5, label='validation accuracy')\n",
    "\n",
    "    plt.fill_between(train_sizes, test_mean + test_std,\n",
    "                     test_mean - test_std, alpha=0.15, color='green')\n",
    "\n",
    "    plt.grid()\n",
    "    plt.xlabel('Number of training samples')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.ylim([0.0, 1.2])\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if(save_result):\n",
    "        plt.savefig('./../Results/learning_curve.png', dpi=300)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### Plot Validation Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def func_validation_curve(est, X_train, y_train, param_name, param_range, scale=True, save_result=False):\n",
    "    train_scores, test_scores = validation_curve(estimator=est, X=X_train, y=y_train, param_name=param_name, \n",
    "                                                     param_range=param_range, cv=10, n_jobs=-1)\n",
    "\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    train_std = np.std(train_scores, axis=1)\n",
    "    test_mean = np.mean(test_scores, axis=1)\n",
    "    test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    plt.plot(param_range, train_mean, \n",
    "             color='blue', marker='o', \n",
    "             markersize=5, label='training accuracy')\n",
    "\n",
    "    plt.fill_between(param_range, train_mean + train_std,\n",
    "                     train_mean - train_std, alpha=0.15,\n",
    "                     color='blue')\n",
    "\n",
    "    plt.plot(param_range, test_mean, \n",
    "             color='green', linestyle='--', \n",
    "             marker='s', markersize=5, \n",
    "             label='validation accuracy')\n",
    "\n",
    "    plt.fill_between(param_range, \n",
    "                     test_mean + test_std,\n",
    "                     test_mean - test_std, \n",
    "                     alpha=0.15, color='green')\n",
    "\n",
    "    plt.grid()\n",
    "    if(scale):\n",
    "        plt.xscale('log')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.xlabel('Parameter ' + param_name)\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim([0.0, 1.2])\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if(save_result):\n",
    "        plt.savefig('./../Results/validation_curve.png', dpi=300)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset (Vehicle silhouettes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "link: http://archive.ics.uci.edu/ml/datasets/Statlog+%28Vehicle+Silhouettes%29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 18 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original variable name</th>\n",
       "      <th>Formula</th>\n",
       "      <th>Column name in the model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COMPACTNESS</td>\n",
       "      <td>(average perim)**2/area</td>\n",
       "      <td>compactness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CIRCULARITY</td>\n",
       "      <td>(average radius)**2/area</td>\n",
       "      <td>circularity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DISTANCE CIRCULARITY</td>\n",
       "      <td>area/(av.distance from border)**2</td>\n",
       "      <td>distance_circularity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RADIUS RATIO</td>\n",
       "      <td>(max.rad-min.rad)/av.radius</td>\n",
       "      <td>radius_ratio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PR.AXIS ASPECT RATIO</td>\n",
       "      <td>(minor axis)/(major axis)</td>\n",
       "      <td>pr_axis_aspect_ratio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MAX.LENGTH ASPECT RATIO</td>\n",
       "      <td>(length perp. max length)/(max length)</td>\n",
       "      <td>max_length_aspect_ratio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SCATTER RATIO</td>\n",
       "      <td>(inertia about minor axis)/(inertia about majo...</td>\n",
       "      <td>scatter_ratio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ELONGATEDNESS</td>\n",
       "      <td>area/(shrink width)**2</td>\n",
       "      <td>elongatedness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PR.AXIS RECTANGULARITY</td>\n",
       "      <td>area/(pr.axis length*pr.axis width)</td>\n",
       "      <td>pr_axis_rectangularity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MAX.LENGTH RECTANGULARITY</td>\n",
       "      <td>area/(max.length*length perp. to this)</td>\n",
       "      <td>max_length_rectangularity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SCALED VARIANCE</td>\n",
       "      <td>(2nd order moment about minor axis)/area ALONG...</td>\n",
       "      <td>scaled_variance1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SCALED VARIANCE</td>\n",
       "      <td>(2nd order moment about major axis)/area ALONG...</td>\n",
       "      <td>scaled_variance2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SCALED RADIUS OF GYRATION</td>\n",
       "      <td>(mavar+mivar)/area</td>\n",
       "      <td>scaled_radius_of_gyration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SKEWNESS ABOUT</td>\n",
       "      <td>(3rd order moment about major axis)/sigma_min*...</td>\n",
       "      <td>skewness_about1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SKEWNESS ABOUT</td>\n",
       "      <td>(3rd order moment about minor axis)/sigma_maj*...</td>\n",
       "      <td>skewness_about2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>KURTOSIS ABOUT</td>\n",
       "      <td>(4th order moment about major axis)/sigma_min*...</td>\n",
       "      <td>kurtosis_about1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>KURTOSIS ABOUT</td>\n",
       "      <td>(4th order moment about minor axis)/sigma_maj*...</td>\n",
       "      <td>kurtosis_about2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>HOLLOWS RATIO</td>\n",
       "      <td>(area of hollows)/(area of bounding polygon)</td>\n",
       "      <td>hollows_ratio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>VEHICLE (OUTPUT VARIABLE)</td>\n",
       "      <td>Possible values: (Opel / Saab / Bus / Van)</td>\n",
       "      <td>vehicle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Original variable name  \\\n",
       "0                 COMPACTNESS   \n",
       "1                 CIRCULARITY   \n",
       "2        DISTANCE CIRCULARITY   \n",
       "3                RADIUS RATIO   \n",
       "4        PR.AXIS ASPECT RATIO   \n",
       "5     MAX.LENGTH ASPECT RATIO   \n",
       "6               SCATTER RATIO   \n",
       "7               ELONGATEDNESS   \n",
       "8      PR.AXIS RECTANGULARITY   \n",
       "9   MAX.LENGTH RECTANGULARITY   \n",
       "10            SCALED VARIANCE   \n",
       "11            SCALED VARIANCE   \n",
       "12  SCALED RADIUS OF GYRATION   \n",
       "13             SKEWNESS ABOUT   \n",
       "14             SKEWNESS ABOUT   \n",
       "15             KURTOSIS ABOUT   \n",
       "16             KURTOSIS ABOUT   \n",
       "17              HOLLOWS RATIO   \n",
       "18  VEHICLE (OUTPUT VARIABLE)   \n",
       "\n",
       "                                              Formula  \\\n",
       "0                             (average perim)**2/area   \n",
       "1                            (average radius)**2/area   \n",
       "2                   area/(av.distance from border)**2   \n",
       "3                         (max.rad-min.rad)/av.radius   \n",
       "4                           (minor axis)/(major axis)   \n",
       "5              (length perp. max length)/(max length)   \n",
       "6   (inertia about minor axis)/(inertia about majo...   \n",
       "7                              area/(shrink width)**2   \n",
       "8                 area/(pr.axis length*pr.axis width)   \n",
       "9              area/(max.length*length perp. to this)   \n",
       "10  (2nd order moment about minor axis)/area ALONG...   \n",
       "11  (2nd order moment about major axis)/area ALONG...   \n",
       "12                                 (mavar+mivar)/area   \n",
       "13  (3rd order moment about major axis)/sigma_min*...   \n",
       "14  (3rd order moment about minor axis)/sigma_maj*...   \n",
       "15  (4th order moment about major axis)/sigma_min*...   \n",
       "16  (4th order moment about minor axis)/sigma_maj*...   \n",
       "17       (area of hollows)/(area of bounding polygon)   \n",
       "18         Possible values: (Opel / Saab / Bus / Van)   \n",
       "\n",
       "     Column name in the model  \n",
       "0                 compactness  \n",
       "1                 circularity  \n",
       "2        distance_circularity  \n",
       "3                radius_ratio  \n",
       "4        pr_axis_aspect_ratio  \n",
       "5     max_length_aspect_ratio  \n",
       "6               scatter_ratio  \n",
       "7               elongatedness  \n",
       "8      pr_axis_rectangularity  \n",
       "9   max_length_rectangularity  \n",
       "10           scaled_variance1  \n",
       "11           scaled_variance2  \n",
       "12  scaled_radius_of_gyration  \n",
       "13            skewness_about1  \n",
       "14            skewness_about2  \n",
       "15            kurtosis_about1  \n",
       "16            kurtosis_about2  \n",
       "17              hollows_ratio  \n",
       "18                    vehicle  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = './../Data/metadata_vehicles.txt'\n",
    "metadata = pd.read_table(file, sep=',', engine='python', header=0)\n",
    "\n",
    "print('The model has', metadata.shape[0]-1, 'columns')\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "directory = './../Data/statlog-vehicle/'\n",
    "vehicles = pd.DataFrame()\n",
    "\n",
    "for f in os.listdir(directory):\n",
    "    file = pd.read_table(directory+f, sep='\\s', engine='python', header=None)\n",
    "    vehicles = pd.concat([vehicles, file])\n",
    "\n",
    "vehicles.columns = metadata['Column name in the model'].values\n",
    "class_names=['bus', 'opel', 'saab', 'van']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High five! You successfuly sent some data to your account on plotly. View your plot in your browser at https://plot.ly/~jaime9510/0 or inside your plot.ly account where it is named 'pandas-box-plot'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~jaime9510/0.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for col in vehicles.columns:\n",
    "    data.append(  go.Box( y=vehicles[col], name=col, showlegend=False ) )\n",
    "\n",
    "data.append( go.Scatter( x = vehicles.columns, y = vehicles.mean(), mode='lines', name='mean' ) )\n",
    "\n",
    "# IPython notebook\n",
    "py.iplot(data, filename='pandas-box-plot')\n",
    "#url = py.plot(data, filename='pandas-box-plot')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_label = {label: idx for idx, label in enumerate(np.unique(vehicles['vehicle']))}\n",
    "class_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vehicles.ix[:,18] = vehicles.ix[:,18].map(class_label)\n",
    "print(vehicles.shape)\n",
    "vehicles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train - Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = vehicles.iloc[:, :-1].values, vehicles.iloc[:, -1].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('X_train size', X_train.shape[0], '- X_test size', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis (PCA) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "X_train_pca = pca.fit_transform(X_train_std)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.bar(range(1, 19), pca.explained_variance_ratio_, alpha=0.5, align='center')\n",
    "plt.step(range(1, 19), np.cumsum(pca.explained_variance_ratio_), where='mid')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal components')\n",
    "plt.savefig('./../Results/PCA.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=9)\n",
    "X_train_pca = pca.fit_transform(X_train_std)\n",
    "print('%', pca.explained_variance_ratio_)\n",
    "print('Varianza spiegata per 9 componenti', sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_pca = pca.transform(X_test_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Discriminant Analysis (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lda = LDA(n_components=None)\n",
    "X_train_lda = lda.fit_transform(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(lda.explained_variance_ratio_ )\n",
    "print(sum(lda.explained_variance_ratio_ ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_lda = lda.transform(X_test_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (X_train_std, X_test_std) (X_train_pca, X_test_pca); (X_train_lda, X_test_lda)\n",
    "\n",
    "X_train_model = X_train_std\n",
    "X_test_model = X_test_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only this model will be implement in two ways. The first one in which it is tested manually the cross-validation process and results; and the second one, that automates the process to find the best parameters for the model using also cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=100.0, random_state=0)\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10,random_state=1).split(X_train_model, y_train)\n",
    "#kfold = KFold(n_splits=10,random_state=1).split(X_train, y_train)\n",
    "\n",
    "scores = []\n",
    "for k, (train, test) in enumerate(kfold):\n",
    "    lr.fit(X_train_model[train], y_train[train])\n",
    "    score = lr.score(X_train_model[test], y_train[test])\n",
    "    scores.append(score)\n",
    "    print('Fold: %s, Accuracy: %.3f' % (k+1, score))\n",
    "    \n",
    "print('\\nCV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr.fit(X_train_model, y_train)\n",
    "print(X_train_model.shape)\n",
    "print('Test accuracy: %.4f' % lr.score(X_test_model, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipelining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe_lr = Pipeline([('lr', LogisticRegression(random_state=0))])\n",
    "\n",
    "param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "\n",
    "param_grid = [{'lr__C': param_range}]\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe_lr, \n",
    "                  param_grid=param_grid, \n",
    "                  scoring='accuracy', \n",
    "                  cv=10,\n",
    "                  n_jobs=-1)\n",
    "\n",
    "gs = gs.fit(X_train_model, y_train)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(gs.cv_results_).to_csv(path_or_buf='./../Results/lr_results.csv', decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c_lr = gs.best_params_.get('lr__C', 1)\n",
    "lr = LogisticRegression(C=c_lr, random_state=0)\n",
    "lr.fit(X_train_model, y_train)\n",
    "\n",
    "print('Train accuracy: %.4f' % lr.score(X_train_model, y_train))\n",
    "print('Test accuracy: %.4f' % lr.score(X_test_model, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ##### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_test_model)\n",
    "confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(confmat, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "plt.figure()\n",
    "plot_confusion_matrix(confmat, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ##### Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "func_learning_curve(lr, X_train_model, y_train, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ##### Validation Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_range = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "param_name = 'C'\n",
    "func_validation_curve(lr, X_train_model, y_train, param_name, param_range, True, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree-Based Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe_dt = Pipeline([('dt', DecisionTreeClassifier(random_state=0))])\n",
    "\n",
    "param_range = [3, 5, 7, 10, 50, 100]\n",
    "\n",
    "param_grid = [{'dt__max_depth': param_range}]\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe_dt, \n",
    "                  param_grid=param_grid, \n",
    "                  scoring='accuracy', \n",
    "                  cv=10,\n",
    "                  n_jobs=-1)\n",
    "\n",
    "gs = gs.fit(X_train_model, y_train)\n",
    "print('Best score: %.4f' % gs.best_score_)\n",
    "print('Best params: %s' % gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(gs.cv_results_).to_csv(path_or_buf='./../Results/dt_results.csv', decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "md = gs.best_params_.get('dt__max_depth', None)\n",
    "\n",
    "tree = DecisionTreeClassifier(criterion='gini', max_depth=md, random_state=0)\n",
    "tree.fit(X_train_model, y_train)\n",
    "\n",
    "print('Train accuracy: %.4f' % tree.score(X_train_model, y_train))\n",
    "print('Test accuracy: %.4f' % tree.score(X_test_model, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ##### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = tree.predict(X_test_model)\n",
    "confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(confmat, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "plt.figure()\n",
    "plot_confusion_matrix(confmat, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ##### Tree graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dot_data = export_graphviz(tree, out_file=None,\n",
    "                feature_names = metadata['Column name in the model'].values,\n",
    "                class_names=['bus', 'opel', 'saab', 'van'],\n",
    "                filled=True, rounded=True)\n",
    "\n",
    "graph = pydotplus.graph_from_dot_data(dot_data) \n",
    "print(graph)\n",
    "display(Image(graph.create_png()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ##### Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "func_learning_curve(tree, X_train_model, y_train, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ##### Validation Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_range = [3, 5, 7, 10, 30, 50, 75, 100]\n",
    "param_name = 'max_depth'\n",
    "func_validation_curve(tree, X_train_model, y_train, param_name, param_range, False, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe_rf = Pipeline([('rf', RandomForestClassifier(criterion='gini', random_state=1))])\n",
    "\n",
    "param_range = [3, 5, 7, 10, 50, 100, 300, 500, 1000]\n",
    "\n",
    "param_grid = [{'rf__n_estimators': param_range}]\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe_rf, \n",
    "                  param_grid=param_grid, \n",
    "                  scoring='accuracy', \n",
    "                  cv=10,\n",
    "                  n_jobs=-1)\n",
    "\n",
    "gs = gs.fit(X_train_model, y_train)\n",
    "\n",
    "print('Best score: %.4f' % gs.best_score_)\n",
    "print('Best params: %s' % gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(gs.cv_results_).to_csv(path_or_buf='./../Results/rf_results.csv', decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ne = gs.best_params_.get('rf__n_estimators', None)\n",
    "forest = RandomForestClassifier(criterion='gini',\n",
    "                                n_estimators=ne, \n",
    "                                random_state=1,\n",
    "                                n_jobs=-1)\n",
    "forest.fit(X_train_model, y_train)\n",
    "\n",
    "print('Train accuracy: %.4f' % forest.score(X_train_model, y_train))\n",
    "print('Test accuracy: %.4f' % forest.score(X_test_model, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ##### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = forest.predict(X_test_model)\n",
    "confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(confmat, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "plt.figure()\n",
    "plot_confusion_matrix(confmat, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ##### Learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "func_learning_curve(forest, X_train_model, y_train, True)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ##### Validation curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_range = [3, 5, 7, 10, 50, 100, 300, 500, 1000]\n",
    "param_name = 'n_estimators'\n",
    "func_validation_curve(forest, X_train_model, y_train, param_name, param_range, False, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe_svm = Pipeline([('svm', SVC(random_state=1))])\n",
    "\n",
    "param_range_C = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "\n",
    "param_grid = [{'svm__C': param_range_C, \n",
    "               'svm__kernel': ['linear']}]\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe_svm, \n",
    "                  param_grid=param_grid, \n",
    "                  scoring='accuracy', \n",
    "                  cv=10,\n",
    "                  n_jobs=-1)\n",
    "\n",
    "gs = gs.fit(X_train_model, y_train)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(gs.cv_results_).to_csv(path_or_buf='./../Results/svm_linear_results.csv', decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = gs.best_params_.get('svc__C', 1)\n",
    "svm = SVC(kernel='linear', C=c, random_state=1)\n",
    "svm.fit(X_train_model, y_train)\n",
    "\n",
    "print('Train accuracy: %.4f' % svm.score(X_train_model, y_train))\n",
    "print('Test accuracy: %.4f' % svm.score(X_test_model, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ##### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = svm.predict(X_test_model)\n",
    "confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(confmat, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "plt.figure()\n",
    "plot_confusion_matrix(confmat, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ##### Learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "func_learning_curve(svm, X_train_model, y_train, True)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ##### Validation curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "param_range = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "param_name = 'C'\n",
    "func_validation_curve(svm, X_train_model, y_train, param_name, param_range, True, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe_svm_rbf = Pipeline([('svm_rbf', SVC(random_state=1))])\n",
    "\n",
    "param_range_gamma = [0.001, 0.01, 0.1, 1.0, 10.0]\n",
    "param_range_c = [0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "\n",
    "param_grid = [{'svm_rbf__C': param_range_c, \n",
    "                  'svm_rbf__gamma': param_range_gamma, \n",
    "                  'svm_rbf__kernel': ['rbf']}]\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe_svm_rbf, \n",
    "                  param_grid=param_grid, \n",
    "                  scoring='accuracy', \n",
    "                  cv=10,\n",
    "                  n_jobs=-1)\n",
    "\n",
    "gs = gs.fit(X_train_model, y_train)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c_rbf = gs.best_params_.get('svm_rbf__C', 1)\n",
    "g = gs.best_params_.get('svm_rbf__gamma', 1)\n",
    "\n",
    "svm_rbf = SVC(kernel='rbf', random_state=0, gamma=g, C=c_rbf)\n",
    "svm_rbf.fit(X_train_model, y_train)\n",
    "\n",
    "print('Train accuracy: %.4f' % svm_rbf.score(X_train_model, y_train))\n",
    "print('Test accuracy: %.4f' % svm_rbf.score(X_test_model, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ##### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = svm_rbf.predict(X_test_model)\n",
    "confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(confmat, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "plt.figure()\n",
    "plot_confusion_matrix(confmat, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ##### Learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "func_learning_curve(svm_rbf, X_train_model, y_train, True)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ##### Validation curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "param_range = [0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "param_name = 'C'\n",
    "func_validation_curve(svm_rbf, X_train_model, y_train, param_name, param_range, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "param_range = [0.001, 0.01, 0.1, 1.0, 10.0]\n",
    "param_name = 'gamma'\n",
    "func_validation_curve(svm_rbf, X_train_model, y_train, param_name, param_range, True, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### Using Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_importance = pd.DataFrame(data=forest.feature_importances_, \n",
    "                             index=vehicles.ix[:,:-1].columns, columns=['Importance'])\n",
    "\n",
    "rf_importance.sort_values(by=['Importance'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### L1-Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(penalty='l1', C=0.1)\n",
    "lr.fit(X_train_model, y_train)\n",
    "print('Training accuracy:', lr.score(X_train_model, y_train))\n",
    "print('Test accuracy:', lr.score(X_test_model, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = pd.DataFrame(lr.coef_)\n",
    "vehicles.columns[p.columns[(p == 0).all()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
